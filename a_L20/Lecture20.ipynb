{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CSS 120: Environmental Data Science\n",
    "\n",
    "## Paleoclimate\n",
    "\n",
    "### Umberto Mignozzetti (UCSD)\n",
    "\n",
    "(Based on Project Pythia and ClimateMatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Today's Lecture\n",
    "\n",
    "1. Paleoclimate proxies (physical characteristics of the environment that can stand in for direct measurements)\n",
    "2. Reconstructions of paleo temperatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# To install\n",
    "# !pip install LiPD --quiet\n",
    "# !pip install pyleoclim --quiet\n",
    "# !pip install climlab --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pooch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import tempfile\n",
    "import lipd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shapereader\n",
    "import pyleoclim as pyleo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Pooch Load\n",
    "def pooch_load(filelocation=None, filename=None, processor=None):\n",
    "    shared_location = \"~/\"\n",
    "    user_temp_cache = tempfile.gettempdir()\n",
    "\n",
    "    if os.path.exists(os.path.join(shared_location, filename)):\n",
    "        file = os.path.join(shared_location, filename)\n",
    "    else:\n",
    "        file = pooch.retrieve(\n",
    "            filelocation,\n",
    "            known_hash=None,\n",
    "            fname=os.path.join(user_temp_cache, filename),\n",
    "            processor=processor,\n",
    "        )\n",
    "\n",
    "    return file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the PAGES2K LiDP files in a pandas.DataFrame\n",
    "def lipd2df(\n",
    "    lipd_dirpath,\n",
    "    pkl_filepath=None,\n",
    "    col_str=[\n",
    "        \"paleoData_pages2kID\", \"dataSetName\", \"archiveType\", \"geo_meanElev\", \"geo_meanLat\",\n",
    "        \"geo_meanLon\", \"year\", \"yearUnits\", \"paleoData_variableName\", \"paleoData_units\",\n",
    "        \"paleoData_values\", \"paleoData_proxy\",\n",
    "    ],\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a bunch of PAGES2k LiPD files to a `pandas.DataFrame` to boost data loading.\n",
    "\n",
    "    If `pkl_filepath` isn't `None`, save the DataFrame as a pikle file.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "        lipd_dirpath: str\n",
    "          Path of the PAGES2k LiPD files\n",
    "        pkl_filepath: str or None\n",
    "          Path of the converted pickle file. Default: `None`\n",
    "        col_str: list of str\n",
    "          Name of the variables to extract from the LiPD files\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "        df: `pandas.DataFrame`\n",
    "          Converted Pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Save the current working directory for later use, as the LiPD utility will change it in the background\n",
    "    work_dir = os.getcwd()\n",
    "    # LiPD utility requries the absolute path\n",
    "    lipd_dirpath = os.path.abspath(lipd_dirpath)\n",
    "    # Load LiPD files\n",
    "    lipds = lipd.readLipd(lipd_dirpath)\n",
    "    # Extract timeseries from the list of LiDP objects\n",
    "    ts_list = lipd.extractTs(lipds)\n",
    "    # Recover the working directory\n",
    "    os.chdir(work_dir)\n",
    "    # Create an empty pandas.DataFrame with the number of rows to be the number of the timeseries (PAGES2k records),\n",
    "    # and the columns to be the variables we'd like to extract\n",
    "    df_tmp = pd.DataFrame(index=range(len(ts_list)), columns=col_str)\n",
    "    # Loop over the timeseries and pick those for global temperature analysis\n",
    "    i = 0\n",
    "    for ts in ts_list:\n",
    "        if (\n",
    "            \"paleoData_useInGlobalTemperatureAnalysis\" in ts.keys()\n",
    "            and ts[\"paleoData_useInGlobalTemperatureAnalysis\"] == \"TRUE\"\n",
    "        ):\n",
    "            for name in col_str:\n",
    "                try:\n",
    "                    df_tmp.loc[i, name] = ts[name]\n",
    "                except:\n",
    "                    df_tmp.loc[i, name] = np.nan\n",
    "            i += 1\n",
    "    # Drop the rows with all NaNs (those not for global temperature analysis)\n",
    "    df = df_tmp.dropna(how=\"all\")\n",
    "    # Save the dataframe to a pickle file for later use\n",
    "    if pkl_filepath:\n",
    "        save_path = os.path.abspath(pkl_filepath)\n",
    "        print(f\"Saving pickle file at: {save_path}\")\n",
    "        df.to_pickle(save_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupressOutputs(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        del self._stringio  # free up some memory\n",
    "        sys.stdout = self._stdout##  Helper functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to PAGES2k\n",
    "\n",
    "There are various types of [paleoclimate archives and proxies](http://wiki.linked.earth/Climate_Proxy) that can be used to reconstruct past changes in Earth's climate. For example:\n",
    "\n",
    "- **Sediment Cores**: Sediments deposited in layers within lakes and oceans serve as a record of climate variations over time.\n",
    "\n",
    "- **Ice Cores**: Similarly to sediment cores, ice cores capture past climate changes in layers of ice accumulated over time. \n",
    "    + Common proxies for reconstructing past climate in ice cores include water isotopes, greenhouse gas concentrations of air bubbles in the ice, and dust.\n",
    "\n",
    "- **Corals**: Corals form annual growth bands within their carbonate skeletons, recording temperature changes over time.\n",
    "\n",
    "- **Speleothems**: These are cave formations that result from the deposition of minerals from groundwater. \n",
    "\n",
    "- **Tree Rings**: Each year, trees add a new layer of growth, known as a tree ring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to PAGES2k\n",
    "\n",
    "There are many existing paleoclimate reconstructions spanning a variety of timescales and from global locations. \n",
    "\n",
    "One way to deal with the multiple sources is compiling all existing paleoclimate records for a single climate variable and over a specific time period.\n",
    "\n",
    "This is the what the **PAGES2k network** do. \n",
    "\n",
    "The database consists of:\n",
    "\n",
    "1. 692 records \n",
    "2. 648 locations\n",
    "3. Variety of archives (e.g., trees, ice, sediment, corals, speleothems, etc.)\n",
    "4; Span the Common Era (1 CE to present, i.e., the past ~2,000 years).\n",
    "\n",
    "You can read more about the PAGES2k network, in [PAGES 2k Consortium (2017)](https://www.nature.com/articles/sdata201788)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Get PAGES2k LiPD Files\n",
    "\n",
    "The PAGES2k network is stored in a specific file format known as [Linked Paleo Data format (LiPD)](http://wiki.linked.earth/Linked_Paleo_Data).\n",
    "\n",
    "LiPD files contain time series information in addition to supporting metadata (e.g., root metadata, location).\n",
    "\n",
    "Pyleoclim (and its dependency package LiPD) leverages this additional information using LiPD-specific functionality.\n",
    "\n",
    "Data stored in the `.lpd` format can be loaded directly as an Lipd object.\n",
    "\n",
    "If the data_path points to *one LiPD file*, `lipd.readLipd.()` will load the specific record.\n",
    "\n",
    "If data_path points to a *folder of LiPD files*, `lipd.readLipd.()` will load the full set of records. \n",
    "\n",
    "This function to read in the data is imbedded in the helper function above used to read the data in and convert it to a more usable format.\n",
    "\n",
    "The first thing we need to do it to download the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Get PAGES2k LiPD Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Set the name to save the PAGES2K data\n",
    "fname = \"pages2k_data\"\n",
    "\n",
    "# Download the data\n",
    "lipd_file_path = pooch.retrieve(\n",
    "    url=\"https://ndownloader.figshare.com/files/8119937\",\n",
    "    known_hash=None,\n",
    "    path=\"./\",\n",
    "    fname=fname,\n",
    "    processor=pooch.Unzip(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Get PAGES2k LiPD Files\n",
    "\n",
    "Now we can use our helper function `lipd_2df()` to convert the LiPD files to a [Pandas dataframe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 139313,
     "status": "ok",
     "timestamp": 1680670246822,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "# convert all the lipd files into a DataFrame\n",
    "fname = \"pages2k_data\"\n",
    "\n",
    "with SupressOutputs():\n",
    "    pages2k_data = lipd2df(\n",
    "        lipd_dirpath=os.path.join(\".\", f\"{fname}.unzip\", \"LiPD_Files\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Get PAGES2k LiPD Files\n",
    "\n",
    "The PAGES2k data is now stored as a dataframe and we can view the data to understand different attributes it contains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1680670283233,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "# print the top few rows of the PAGES2K data\n",
    "pages2k_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plotting a Map of Proxy Reconstruction Locations\n",
    "\n",
    "Now that we have converted the data into a Pandas dataframe, we can plot the PAGES2k network on a map to understand the spatial distribution of the temperature records and the types of proxies that were measured.\n",
    "\n",
    "Before generating the plot, we have to define the colours and the marker types that we want to use in the plot.\n",
    "\n",
    "We also need to set a list with the different `archive_type` names that appear in the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plotting a Map of Proxy Reconstruction Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 5407,
     "status": "ok",
     "timestamp": 1680670611982,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "# Markers and colors\n",
    "markers = [\"p\", \"p\", \"o\", \"v\", \"d\", \"*\", \"s\", \"s\", \"8\", \"D\", \"^\"]\n",
    "colors = [\n",
    "    np.array([1.0, 0.83984375, 0.0]),\n",
    "    np.array([0.73828125, 0.71484375, 0.41796875]),\n",
    "    np.array([1.0, 0.546875, 0.0]),\n",
    "    np.array([0.41015625, 0.41015625, 0.41015625]),\n",
    "    np.array([0.52734375, 0.8046875, 0.97916667]),\n",
    "    np.array([0.0, 0.74609375, 1.0]),\n",
    "    np.array([0.25390625, 0.41015625, 0.87890625]),\n",
    "    np.array([0.54296875, 0.26953125, 0.07421875]),\n",
    "    np.array([1, 0, 0]),\n",
    "    np.array([1.0, 0.078125, 0.57421875]),\n",
    "    np.array([0.1953125, 0.80078125, 0.1953125]),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plotting a Map of Proxy Reconstruction Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 5407,
     "status": "ok",
     "timestamp": 1680670611982,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
    "ax.set_title(f\"PAGES2k Network (n={len(pages2k_data)})\", fontsize=20, fontweight=\"bold\")\n",
    "ax.set_global()\n",
    "ax.coastlines()\n",
    "ax.add_feature(cfeature.LAND, facecolor=\"gray\", alpha=0.3)\n",
    "ax.gridlines(edgecolor=\"gray\", linestyle=\":\")\n",
    "\n",
    "# plot the different archive types\n",
    "archive_types = pages2k_data.archiveType.unique()\n",
    "for i, type_i in enumerate(archive_types):\n",
    "    df = pages2k_data[pages2k_data[\"archiveType\"] == type_i]\n",
    "    # count the number of appearances of the same archive_type\n",
    "    count = df[\"archiveType\"].count()\n",
    "    # generate the plot\n",
    "    ax.scatter(df[\"geo_meanLon\"],df[\"geo_meanLat\"],marker=markers[i],c=colors[i],\n",
    "        edgecolor=\"k\",s=50,transform=ccrs.Geodetic(),label=f\"{type_i} (n = {count})\",)\n",
    "\n",
    "# Legend\n",
    "ax.legend(scatterpoints=1, bbox_to_anchor=(0, -0.4),loc=\"lower left\",ncol=3,fontsize=15,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reconstructing Past Changes in Ocean Climate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview of Isotopes in Paleoclimate\n",
    "\n",
    "Oxygen isotopes of corals can record changes in temperature associated with the phase of ENSO further back in time.\n",
    "\n",
    "The two oxygen isotopes that are most commonly used in paleoclimate are oxygen 16 (<sup>16</sup>O), which is the which is the **\"lighter\"** oxygen isotope, and oxygen 18 (<sup>16</sup>O), which is the **\"heavier\"** oxygen isotope. \n",
    "\n",
    "![image-1.png](https://github.com/ClimateMatchAcademy/course-content/blob/main/tutorials/W1D4_Paleoclimate/images/t2_image1.png?raw=true)\n",
    "\n",
    "Credit: [NASA Climate Science Investigations](https://www.ces.fau.edu/nasa/module-3/how-is-temperature-measured/isotopes.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview of Isotopes in Paleoclimate\n",
    "\n",
    "The two hydrogen isotopes that are most commonly used in paleoclimate are hydrogen (H), which is the **\"lighter\"** oxygen isotope, and deuterium (D), which is the **\"heavier\"** oxygen isotope. \n",
    "\n",
    "![image-2.png](https://github.com/ClimateMatchAcademy/course-content/blob/main/tutorials/W1D4_Paleoclimate/images/t2_image2.png?raw=true)\n",
    "\n",
    "Credit: [NASA Climate Science Investigations](https://www.ces.fau.edu/nasa/module-3/how-is-temperature-measured/isotopes.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview of Isotopes in Paleoclimate\n",
    "\n",
    "Changes in the ratio of the heavy to light isotope can reflect changes in different climate variables, depending on geographic location and the material being measured.\n",
    "\n",
    "The ratio represented in delta notation (δ) and in units of per mille (‰), and is calculated using the equation below (the same applies to the ratio of the heavy and light hydrogen isotopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assessing Variability Related to El Niño Using Pyleoclim Series\n",
    "\n",
    "ENSO is a recurring climate pattern involving changes in SST in the central and eastern tropical Pacific Ocean.\n",
    "\n",
    "Oxygen isotopes ([&delta;<sup>18</sup>O](https://en.wikipedia.org/wiki/Δ18O)) of corals are a commonly used proxy for reconstructing changes in tropical Pacific SST and ENSO.\n",
    "\n",
    "Long-lived corals are well-suited for studying paleo-ENSO variability because they store decades to centuries of sub-annually resolved proxy information in the tropical Pacific. \n",
    "\n",
    "The oxygen isotopes of corals are useful for studying ENSO because they record changes in sea-surface temperature (SST), with more positive values of &delta;<sup>18</sup>O corresponding to colder SSTs, and vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assessing Variability Related to El Niño Using Pyleoclim Series\n",
    "\n",
    "One approach for detecting ENSO from coral isotope data is applying a 2- to 7-year bandpass filter to the &delta;<sup>18</sup>O records to highlight ENSO-related variability and compare (quantitatively) the bandpassed coral records to the Oceanic Niño Index (ONI). \n",
    "\n",
    "While we won't be going into this amount of detail, you may utilize the methods sections of these papers as a guide: [Cobb et al.(2003)](https://www.nature.com/articles/nature01779), [Cobb et al.(2013)](https://www.science.org/doi/10.1126/science.1228246).\n",
    "\n",
    "Let us look at the &delta;<sup>18</sup>O records and comparing to a plot of the ONI without this band-pass filtering, in part to highlight why the filtering is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load coral oxygen isotope proxy reconstructions\n",
    "\n",
    "The two coral records we'll look at are from [Palmyra Atoll](https://en.wikipedia.org/wiki/Palmyra_Atoll) and [Line Islands](https://en.wikipedia.org/wiki/Line_Islands), both of which are in the tropical central Pacific Ocean.\n",
    "\n",
    "Let's plot these approximate locations as well as the Niño 3.4 region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 6))\n",
    "ax = plt.axes(projection=ccrs.Robinson(central_longitude=180))\n",
    "ax.stock_img()\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "# Niño 3.4 region\n",
    "rectangle = patches.Rectangle((170, -5),50,10,transform=ccrs.Geodetic(),\n",
    "    edgecolor=\"k\",facecolor=\"none\",linewidth=3,)\n",
    "ax.add_patch(rectangle)\n",
    "\n",
    "rx, ry = rectangle.get_xy()\n",
    "cx = rx + rectangle.get_width() / 2.0\n",
    "cy = ry + rectangle.get_height() / 2.0\n",
    "\n",
    "# add labels\n",
    "ax.annotate(\n",
    "    \"Nino 3.4\",\n",
    "    (cx - 10, cy),\n",
    "    color=\"w\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    weight=\"bold\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    ")\n",
    "\n",
    "# add the proxy locations\n",
    "ax.scatter(\n",
    "    [-162.078333], [5.883611], transform=ccrs.Geodetic(), s=50, marker=\"v\", color=\"w\"\n",
    ")\n",
    "ax.scatter([-157.2], [1.7], transform=ccrs.Geodetic(), s=50, marker=\"v\", color=\"w\")\n",
    "\n",
    "# add labels\n",
    "ax.annotate(\"Palmyra Atoll\", (-170, 10),\n",
    "    color=\"w\",transform=ccrs.Geodetic(),\n",
    "    weight=\"bold\",fontsize=10,\n",
    "    ha=\"center\",va=\"center\",\n",
    ")\n",
    "\n",
    "ax.annotate(\n",
    "    \"Line Islands\", (-144, -1),\n",
    "    color=\"w\",transform=ccrs.Geodetic(),\n",
    "    weight=\"bold\",fontsize=10,\n",
    "    ha=\"center\", va=\"center\",\n",
    ")\n",
    "\n",
    "# change the map view to zoom in on central Pacific\n",
    "ax.set_extent((120, 300, -25, 25), crs=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load coral oxygen isotope proxy reconstructions\n",
    "\n",
    "To analyze and visualize paleoclimate proxy time series, we will be using [Pyleoclim](https://pyleoclim-util.readthedocs.io/en/latest/).\n",
    "\n",
    "Pycleoclim is specifically designed for the analysis of paleoclimate data. \n",
    "\n",
    "The package is designed around object-oriented `Series`, which can be directly manipulated for plotting and time series-appropriate analysis and operation. \n",
    "\n",
    "The `Series` object describes the fundamentals of a time series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load coral oxygen isotope proxy reconstructions\n",
    "\n",
    "To create a Pyleoclim `Series`, we first need to load the data set, and then specify values for its various properties:\n",
    "\n",
    "*   `time`: Time values for the time series\n",
    "*   `value`: Paleo values for the time series\n",
    "*   `time_name` (optional): Name of the time vector, (e.g., 'Time', 'Age'). This is used to label the x-axis on plots\n",
    "*   `time_unit` (optional): The units of the time axis (e.g., 'years')\n",
    "*   `value_name` (optional): The name of the paleo variable (e.g., 'Temperature')\n",
    "*   `value_unit` (optional): The units of the paleo variable (e.g., 'deg C')\n",
    "*   `label` (optional): Name of the time series (e.g., 'Nino 3.4')\n",
    "*   `clean_ts` (optional): If True (default), remove NaNs and set an increasing time axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load coral oxygen isotope proxy reconstructions\n",
    "\n",
    "A common data format for datasets downloaded from the NOAA Paleoclimate Database is a templated text file, which contains helpful data and metadata. \n",
    "\n",
    "Take a look at our two datasets [here](https://www.ncei.noaa.gov/pub/data/paleo/coral/east_pacific/palmyra_2003.txt) and [here](https://www.ncei.noaa.gov/pub/data/paleo/coral/east_pacific/cobb2013-fan-modsplice-noaa.txt).\n",
    "\n",
    "The functionality in python allows us to ignore all of the information at the beginning of the text files, and we can load the data directly into a `pandas.DataFrame` using `.read_csv()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load Palmyra coral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1681584691666,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "# download the data using the url\n",
    "filename_Palmyra = \"palmyra_2003.txt\"\n",
    "url_Palmyra = (\n",
    "    \"https://www.ncei.noaa.gov/pub/data/paleo/coral/east_pacific/palmyra_2003.txt\"\n",
    ")\n",
    "data_path = pooch_load(\n",
    "    filelocation=url_Palmyra, filename=filename_Palmyra\n",
    ")  # open the file\n",
    "\n",
    "# from the data set, we only want the data related to Modern Living Coral.\n",
    "# this data is between row 6190 and 7539 of the dataset\n",
    "rows = [int(row) for row in np.linspace(6190, 7539, 7539 - 6190 + 1)]\n",
    "\n",
    "# use pandas to read in the csv file\n",
    "palmyra = pd.read_csv(\n",
    "    data_path,\n",
    "    skiprows=lambda x: x\n",
    "    not in rows,  # number of rows to skip based on definition of rows above\n",
    "    sep=\"\\s+\",  # how the data values are seperated (delimited) : '\\s+' = space\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    names=[\"CalendarDate\", \"d180\"],\n",
    "    header=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load Palmyra coral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palmyra.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Load Palmyra coral data\n",
    "\n",
    "Now that we have the data in a dataframe, we can pull the relevant columns of this datframe into a `Series` object in Pyleoclim, which will allow us to organize the relevant metadata so that we can get a well-labeled, publication-quality plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "ts_palmyra = pyleo.Series(\n",
    "    time=palmyra[\"CalendarDate\"],\n",
    "    value=palmyra[\"d180\"],\n",
    "    time_name=\"Calendar date\",\n",
    "    time_unit=\"Years\",\n",
    "    value_name=r\"$d18O$\",\n",
    "    value_unit=\"per mille\",\n",
    "    label=\"Palmyra Coral\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Load Palmyra coral data\n",
    "\n",
    "Since we want to compare datasets based on different measurements (coral &delta;<sup>18</sup>O and the ONI, i.e., a temperature anomaly), it's helpful to standardize the data by removing it's estimated mean and dividing by its estimated standard deviation. \n",
    "\n",
    "Thankfully Pyleoclim has a [function](https://pyleoclim-util.readthedocs.io/en/v0.7.4/core/ui.html#pyleoclim.core.ui.Series.standardize) to do that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "palmyra_stnd = ts_palmyra.standardize()\n",
    "palmyra_stnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load Line Island coral data\n",
    "\n",
    "We will repeat these steps for the other dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Download the data using the url\n",
    "filename_cobb2013 = \"cobb2013-fan-modsplice-noaa.txt\"\n",
    "url_cobb2013 = \"https://www.ncei.noaa.gov/pub/data/paleo/coral/east_pacific/cobb2013-fan-modsplice-noaa.txt\"\n",
    "data_path2 = pooch_load(\n",
    "    filelocation=url_cobb2013, filename=filename_cobb2013\n",
    ")  # open the file\n",
    "\n",
    "# From the data set, we only want the data related to Modern Living Coral.\n",
    "# So this data is between row 6190 and 7539 of the dataset\n",
    "rows = [int(row) for row in np.linspace(127, 800, 800 - 127 + 1)]\n",
    "line = pd.read_csv(\n",
    "    data_path2,\n",
    "    skiprows=lambda x: x not in rows,\n",
    "    sep=\"\\s+\",\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    names=[\"age\", \"d18O\"],\n",
    "    header=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load Line Island coral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load Line Island coral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "ts_line = pyleo.Series(\n",
    "    time=line[\"age\"],\n",
    "    value=line[\"d18O\"],\n",
    "    time_name=\"Calendar date\",\n",
    "    time_unit=\"Years\",\n",
    "    value_name=r\"$d18O$\",\n",
    "    value_unit=\"per mille\",\n",
    "    label=\"Line Island Coral\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load Line Island coral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "line_stnd = ts_line.standardize()\n",
    "line_stnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plot the Data Using Multiseries\n",
    "\n",
    "We will utilize the built in features of a [multiseries](https://pyleoclim-util.readthedocs.io/en/latest/core/api.html#multipleseries-pyleoclim-multipleseries) object to plot our coral proxy data side by side.\n",
    "\n",
    "To create a `pyleo.MultipleSeries`, we first create a list with our `pyleo.Series` objects and then pass this into a `pyleo.MultipleSeries`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# combine into a list\n",
    "nino_comparison = [palmyra_stnd, line_stnd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plot the Data Using Multiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# create multiseries\n",
    "nino = pyleo.MultipleSeries(nino_comparison, name=\"El Nino Comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plot the Data Using Multiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 942,
     "status": "ok",
     "timestamp": 1681584722114,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "# plot the time series of both datasets\n",
    "fig, ax = nino.stackplot(time_unit=\"year\", xlim=[1960, 2000], colors=[\"b\", \"g\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Your turn\n",
    "\n",
    "Recall that as SST becomes colder, &delta;<sup>18</sup>O becomes more positive, and vice versa. Compare the figure below of the ONI to the time series of coral &delta;<sup>18</sup>O you plotted above and answer the questions below.\n",
    "\n",
    "![](https://climatedataguide.ucar.edu/sites/default/files/styles/extra_large/public/2022-03/indices_oni_2_2_lg.png?itok=Zew3VK_4)\n",
    "\n",
    "Credit: [UCAR](https://climatedataguide.ucar.edu/sites/default/files/styles/extra_large/public/2022-03/indices_oni_2_2_lg.png?itok=Zew3VK_4)\n",
    "\n",
    "1. Do the ENSO events recorded by the ONI agree with the coral data?\n",
    "2. What are some considerations you can think of when comparing proxies such as this to the ONI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Make Warming Stripes Plot\n",
    "\n",
    "We can also make a warming stripe for this data `Series` using the [`.stripes()`](https://pyleoclim-util.readthedocs.io/en/latest/core/api.html#pyleoclim.core.multipleseries.MultipleSeries.stripes) method, where darker red stripes indicate a warmer eastern Pacific and possibly an El Niño phase, and darker blue stripes indicate a cooler eastern Pacific and possibly La Niña phase.\n",
    "\n",
    "Can you see the trend present in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1681584728212,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = nino.stripes(\n",
    "    ref_period=(1960, 1990), time_unit=\"year\", show_xaxis=True, cmap=\"RdBu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## See you next class!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W1D4_Tutorial1",
   "provenance": [
    {
     "file_id": "1lHuVrVtAW4fQzc0dFdlZuwY0i71KWw_t",
     "timestamp": 1677637469824
    }
   ],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
